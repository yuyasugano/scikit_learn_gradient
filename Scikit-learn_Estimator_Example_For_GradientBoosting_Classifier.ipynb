{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution role is arn:aws:iam::251344623468:role/service-role/AmazonSageMaker-ExecutionRole-20191017T203175\n",
      "Success - the MySageMakerInstance is in the ap-northeast-1.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sagemaker import get_execution_role\n",
    "import boto3, sys, os\n",
    "import sagemaker\n",
    "\n",
    "# S3 prefix\n",
    "bucket = 'sagemaker-getting-start-test'\n",
    "prefix = 'sagemaker/sklearn-gradient'\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Execution role is \" + role)\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error:  An error occurred (IllegalLocationConstraintException) when calling the CreateBucket operation: The unspecified location constraint is incompatible for the region specific endpoint this request was sent to.\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    if my_region == 'ap-northeast-1':\n",
    "        s3.create_bucket(Bucket=bucket)\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucket, CreateBucketConfiguration={'LocationConstraint': my_region})\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (1440, 5)\n",
      "Index(['open', 'high', 'low', 'close', 'volume'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:00:00</th>\n",
       "      <td>818995</td>\n",
       "      <td>818995</td>\n",
       "      <td>818995</td>\n",
       "      <td>818995</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:01:01</th>\n",
       "      <td>818995</td>\n",
       "      <td>819010</td>\n",
       "      <td>818995</td>\n",
       "      <td>819010</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:02:02</th>\n",
       "      <td>819955</td>\n",
       "      <td>820518</td>\n",
       "      <td>819955</td>\n",
       "      <td>820515</td>\n",
       "      <td>1.4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:03:03</th>\n",
       "      <td>820514</td>\n",
       "      <td>820523</td>\n",
       "      <td>820514</td>\n",
       "      <td>820518</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:04:04</th>\n",
       "      <td>820519</td>\n",
       "      <td>820519</td>\n",
       "      <td>820518</td>\n",
       "      <td>820518</td>\n",
       "      <td>0.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:05:05</th>\n",
       "      <td>820519</td>\n",
       "      <td>820519</td>\n",
       "      <td>820518</td>\n",
       "      <td>820518</td>\n",
       "      <td>0.5341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:06:06</th>\n",
       "      <td>820518</td>\n",
       "      <td>820518</td>\n",
       "      <td>820518</td>\n",
       "      <td>820518</td>\n",
       "      <td>0.3407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:07:07</th>\n",
       "      <td>820518</td>\n",
       "      <td>820519</td>\n",
       "      <td>820000</td>\n",
       "      <td>820518</td>\n",
       "      <td>3.6664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:08:08</th>\n",
       "      <td>820500</td>\n",
       "      <td>820524</td>\n",
       "      <td>820500</td>\n",
       "      <td>820524</td>\n",
       "      <td>1.4373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:09:09</th>\n",
       "      <td>820524</td>\n",
       "      <td>821234</td>\n",
       "      <td>820524</td>\n",
       "      <td>821234</td>\n",
       "      <td>3.9741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close  volume\n",
       "2019-12-07 00:00:00  818995  818995  818995  818995  0.0110\n",
       "2019-12-07 00:01:01  818995  819010  818995  819010  0.2255\n",
       "2019-12-07 00:02:02  819955  820518  819955  820515  1.4304\n",
       "2019-12-07 00:03:03  820514  820523  820514  820518  0.9708\n",
       "2019-12-07 00:04:04  820519  820519  820518  820518  0.3200\n",
       "2019-12-07 00:05:05  820519  820519  820518  820518  0.5341\n",
       "2019-12-07 00:06:06  820518  820518  820518  820518  0.3407\n",
       "2019-12-07 00:07:07  820518  820519  820000  820518  3.6664\n",
       "2019-12-07 00:08:08  820500  820524  820500  820524  1.4373\n",
       "2019-12-07 00:09:09  820524  821234  820524  821234  3.9741"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "api_url_base = 'https://public.bitbank.cc'\n",
    "pair = 'btc_jpy'\n",
    "period = '1min'\n",
    "\n",
    "today = datetime.today()\n",
    "yesterday = today - timedelta(days=1)\n",
    "yesterday = \"{0:%Y%m%d}\".format(yesterday)\n",
    "\n",
    "def api_ohlcv(timestamp):\n",
    "    api_url = '{0}/{1}/candlestick/{2}/{3}'.format(api_url_base, pair, period, timestamp)\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        ohlcv = json.loads(response.content.decode('utf-8'))['data']['candlestick'][0]['ohlcv']\n",
    "        return ohlcv\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "ohlcv = api_ohlcv(yesterday)\n",
    "open, high, low, close, volume, timestamp = [],[],[],[],[],[]\n",
    "for i in ohlcv:\n",
    "    open.append(int(i[0]))\n",
    "    high.append(int(i[1]))\n",
    "    low.append(int(i[2]))\n",
    "    close.append(int(i[3]))\n",
    "    volume.append(float(i[4]))\n",
    "    time_str = str(i[5])\n",
    "    timestamp.append(datetime.fromtimestamp(int(time_str[:10])).strftime('%Y/%m/%d %H:%M:%M'))\n",
    "\n",
    "date_time_index = pd.to_datetime(timestamp) # convert to DateTimeIndex type\n",
    "df = pd.DataFrame({'open': open, 'high': high, 'low': low, 'close': close, 'volume': volume}, index=date_time_index)\n",
    "print(\"DataFrame shape: {}\".format(df.shape))\n",
    "print(df.columns)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "X shape: (1440,5)\n",
      "y shape: (1440,1)\n",
      "----------------------------------------------------------------------------------------\n",
      "y\n",
      "-1    264\n",
      " 0    912\n",
      " 1    264\n",
      "dtype: int64\n",
      "y=1 up, y=0 stay, y=-1 down\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# labelling\n",
    "f = lambda x: 1 if x>0.0001 else -1 if x<-0.0001 else 0 if -0.0001<=x<=0.0001 else np.nan\n",
    "y = df.rename(columns={'close': 'y'}).loc[:, 'y'].pct_change(1).shift(-1).fillna(0)\n",
    "X = df.copy()\n",
    "y_ = pd.DataFrame(y.map(f), columns=['y'])\n",
    "df_ = pd.concat([X, y_], axis=1)\n",
    "\n",
    "# check the shape\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('X shape: (%i,%i)' % X.shape)\n",
    "print('y shape: (%i,%i)' % y_.shape)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y_.groupby('y').size())\n",
    "print('y=1 up, y=0 stay, y=-1 down')\n",
    "print('----------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default buckert: sagemaker-ap-northeast-1-251344623468\n"
     ]
    }
   ],
   "source": [
    "# Create directory and write csv\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "df_.to_csv(\"./data/ohlcv.csv\", header=False, index=False)\n",
    "\n",
    "# Upload the csv file to S3\n",
    "WORK_DIRECTORY = 'data'\n",
    "print(\"Default buckert: {}\".format(sagemaker_session.default_bucket()))\n",
    "train_input = sagemaker_session.upload_data(\"./data/ohlcv.csv\", key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator object: <sagemaker.sklearn.estimator.SKLearn object at 0x7fa929431588>\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "script_path = 'scikit_learn_gradient.py'\n",
    "\n",
    "# Initialise SDK\n",
    "sklearn_estimator = SKLearn(\n",
    "        entry_point=script_path,\n",
    "        role = role,\n",
    "        train_instance_type=\"ml.c4.xlarge\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        output_path=\"s3://{}/output\".format(sagemaker_session.default_bucket())\n",
    ")\n",
    "\n",
    "print(\"Estimator object: {}\".format(sklearn_estimator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-08 02:57:07 Starting - Starting the training job...\n",
      "2019-12-08 02:57:09 Starting - Launching requested ML instances......\n",
      "2019-12-08 02:58:12 Starting - Preparing the instances for training...\n",
      "2019-12-08 02:59:01 Downloading - Downloading input data...\n",
      "2019-12-08 02:59:37 Training - Training image download completed. Training in progress...\u001b[34m2019-12-08 02:59:38,570 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:38,572 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:38,582 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:38,851 sagemaker-containers INFO     Module scikit_learn_gradient does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:38,851 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:38,851 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:38,852 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: scikit-learn-gradient\n",
      "  Building wheel for scikit-learn-gradient (setup.py): started\n",
      "  Building wheel for scikit-learn-gradient (setup.py): finished with status 'done'\n",
      "  Created wheel for scikit-learn-gradient: filename=scikit_learn_gradient-1.0.0-py2.py3-none-any.whl size=8351 sha256=18a412f3d6ff903900796261c50befa7d8a6eb9a2e3405807da7e0c441cf6a7c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4d2hvwk0/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built scikit-learn-gradient\u001b[0m\n",
      "\u001b[34mInstalling collected packages: scikit-learn-gradient\u001b[0m\n",
      "\u001b[34mSuccessfully installed scikit-learn-gradient-1.0.0\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:40,202 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:40,217 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2019-12-08-02-57-06-847\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-251344623468/sagemaker-scikit-learn-2019-12-08-02-57-06-847/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"scikit_learn_gradient\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"scikit_learn_gradient.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=scikit_learn_gradient.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=scikit_learn_gradient\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-251344623468/sagemaker-scikit-learn-2019-12-08-02-57-06-847/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2019-12-08-02-57-06-847\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-251344623468/sagemaker-scikit-learn-2019-12-08-02-57-06-847/source/sourcedir.tar.gz\",\"module_name\":\"scikit_learn_gradient\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"scikit_learn_gradient.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m scikit_learn_gradient\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mGradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\u001b[0m\n",
      "\u001b[34m2019-12-08 02:59:41,971 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-12-08 02:59:50 Uploading - Uploading generated training model\n",
      "2019-12-08 02:59:50 Completed - Training job completed\n",
      "Training seconds: 49\n",
      "Billable seconds: 49\n"
     ]
    }
   ],
   "source": [
    "# Run model training job\n",
    "sklearn_estimator.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# Deploy trained model to an endpoint\n",
    "predictor = sklearn_estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\", endpoint_name=\"sagemaker-scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "The last minute feature selections is below:\n",
      "                       open    high     low   close  volume\n",
      "2019-12-08 03:15:15  804035  804035  804000  804000   0.299\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today()\n",
    "today = \"{0:%Y%m%d}\".format(today)\n",
    "\n",
    "ohlcv = api_ohlcv(today)\n",
    "open, high, low, close, volume, timestamp = [],[],[],[],[],[]\n",
    "for i in ohlcv:\n",
    "    open.append(int(i[0]))\n",
    "    high.append(int(i[1]))\n",
    "    low.append(int(i[2]))\n",
    "    close.append(int(i[3]))\n",
    "    volume.append(float(i[4]))\n",
    "    time_str = str(i[5])\n",
    "    timestamp.append(datetime.fromtimestamp(int(time_str[:10])).strftime('%Y/%m/%d %H:%M:%M'))\n",
    "\n",
    "date_time_index = pd.to_datetime(timestamp) # convert to DateTimeIndex type\n",
    "df_t = pd.DataFrame({'open': open, 'high': high, 'low': low, 'close': close, 'volume': volume}, index=date_time_index)\n",
    "\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('The last minute feature selections is below:')\n",
    "print(df_t.tail(1))\n",
    "input_X = df_t.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n",
      "Next minute prediction is: [0]\n"
     ]
    }
   ],
   "source": [
    "print(type(input_X))\n",
    "print(type(input_X.values))\n",
    "prediction = predictor.predict(input_X.values.reshape(1,-1))\n",
    "print(\"Next minute prediction is: {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
